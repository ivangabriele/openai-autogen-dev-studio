{
  // ―――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――
  // Brave Search API Key

  // Used by agent function `search_web()` which agents can use to help with their task
  // https://brave.com/search/api/ (there is a free plan)
  // "Data for AI" plan is prefered over "Data for Search" since it includes some useful additional props
  "brave_search_api_key": "[BRAVE_SEARCH_API_KEY]",

  // ―――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――
  // Current Model

  // Selected `model` that agents must use in the list of OpenAI API endpoints
  "current_model": "Open-Orca/Mistral-7B-OpenOrca",

  // ―――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――
  // Project Description

  // Description of the program you want the agents to develop
  // You can also set it to `null` if you want the Product Owner agent
  // to prompt you for your project desciption each time you run OADS.
  "initial_project_description": "Create a \"guess the number\" CLI game in Python.",

  // ―――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――
  // List of OpenAI-Compatible API endpoints

  // The `model` key must be unique.
  // https://microsoft.github.io/FLAML/docs/reference/autogen/oai/completion/#create
  "models": [
    // You can deploy it in one click using this Github repository: https://github.com/ivangabriele/docker-llm.
    // FUNCTIONS ARE NOT SUPPORTED BY MOST OPEN SOURCE LLMS (YET?):
    // This is why we use a second endpoint — a Functionary LLM behind a vLLM OpenAI-Compatible API —
    // in order to give Function Calling abilities to almost any smart-enough open-source LLM.

    // This can be also be any inference endpoint compatible following OpenAI API specs,
    // regardless of the model you use behind it.
    {
      "model": "Open-Orca/Mistral-7B-OpenOrca",
      "api_base": "https://[YOUR_CONTAINER_ID]-8000.proxy.runpod.net", // or your public endpoint
      "api_key": "None", // Dummy API Key since it can neither be `null` nor empty
      "api_type": "open_ai"
    }
  ],

  // ―――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――
  // Funtionary LLM API Endpoint Configuration

  // This must be a secondary deployment. Don't use this endpoint in `models`.
  // You can deploy it in one click using this Github repository: https://github.com/ivangabriele/docker-functionary.
  "functionary_model": {
    "model": "musabgultekin/functionary-7b-v1",
    "api_base": "https://[YOUR_CONTAINER_ID]-8000.proxy.runpod.net/v1",
    "api_key": "None", // Dummy API Key since it can neither be `null` nor empty
    "api_type": "open_ai"
  }
}
